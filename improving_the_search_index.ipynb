{
 "metadata": {
  "name": "",
  "signature": "sha256:439a10b81b360bade5c2ea2b77d1ef2eb674efb4d6890da1d70f1e99a161429c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Improving the Search Index"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Inspired by and borrowed heavily from: Collective Intelligence - [Lu\u00eds F. Sim\u00f5es](mailto:luis.simoes@vu.nl)  \n",
      "IR version and assignments by J.E. Hoeksema, 2014-11-12\n",
      "\n",
      "*******"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook's purpose is to improve the search index and query functions built in the previous notebook and assignments"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Loading the Data, Defining some functions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This section is copied from the previous notebook."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle, bz2, re\n",
      "from collections import namedtuple, defaultdict, Counter\n",
      "from IPython.display import display, HTML\n",
      "from math import log10\n",
      "\n",
      "data_path = './' # e.g. 'C:\\Downloads\\' (includes trailing slash)\n",
      "\n",
      "Summaries_file = data_path + 'evolution__Summaries.pkl.bz2'\n",
      "Abstracts_file = data_path + 'evolution__Abstracts.pkl.bz2'\n",
      "\n",
      "Summaries = cPickle.load( bz2.BZ2File( Summaries_file, 'rb' ) )\n",
      "Abstracts = cPickle.load( bz2.BZ2File( Abstracts_file, 'rb' ) )\n",
      "\n",
      "paper = namedtuple( 'paper', ['title', 'authors', 'year', 'doi'] )\n",
      "for (id, paper_info) in Summaries.iteritems():\n",
      "    Summaries[id] = paper( *paper_info )\n",
      "    \n",
      "def display_summary( id, extra_text='' ): # For a non-notebook version: see the Discussion Board\n",
      "    \"\"\"\n",
      "    Function for printing a paper's summary through IPython's Rich Display System.\n",
      "    Trims long titles or author lists, and links to the paper's  DOI (when available).\n",
      "    \"\"\"\n",
      "    s = Summaries[ id ]\n",
      "    \n",
      "    title = ( s.title if s.title[-1]!='.' else s.title[:-1] )\n",
      "    title = title[:150].rstrip() + ('' if len(title)<=150 else '...')\n",
      "    if s.doi!='':\n",
      "        title = '<a href=http://dx.doi.org/%s>%s</a>' % (s.doi, title)\n",
      "    \n",
      "    authors = ', '.join( s.authors[:5] ) + ('' if len(s.authors)<=5 else ', ...')\n",
      "    \n",
      "    lines = [\n",
      "        title,\n",
      "        authors,\n",
      "        str(s.year),\n",
      "        '<small>id: %d%s</small>' % (id, extra_text)\n",
      "        ]\n",
      "    \n",
      "    display( HTML( '<blockquote>%s</blockquote>' % '<br>'.join(lines) ) )\n",
      "    \n",
      "def display_abstract( id, highlights=[]): # For a non-notebook version: see the Discussion Board\n",
      "    \"\"\"\n",
      "    Function for displaying an abstract. Includes optional (naive) highlighting\n",
      "    \"\"\"\n",
      "    a = Abstracts[ id ]\n",
      "    for h in highlights:\n",
      "        a = re.sub(r'\\b(%s)\\b'%h,'<mark>\\\\1</mark>',a, flags=re.IGNORECASE)\n",
      "    display( HTML( '<blockquote>%s</blockquote' % a ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tokenize(text):\n",
      "    \"\"\"\n",
      "    Function that tokenizes a string in a rather naive way. Can be extended later.\n",
      "    \"\"\"\n",
      "    return text.split(' ')\n",
      "\n",
      "def preprocess(tokens):\n",
      "    \"\"\"\n",
      "    Perform linguistic preprocessing on a list of tokens. Can be extended later.\n",
      "    \"\"\"\n",
      "    result = []\n",
      "    for token in tokens:\n",
      "        result.append(token.lower())\n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inverted_index = defaultdict(set)\n",
      "\n",
      "# Takes a while\n",
      "for (id, abstract) in Abstracts.iteritems():\n",
      "    for term in preprocess(tokenize(abstract)):\n",
      "        inverted_index[term].add(id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Short (one-liner) versions of and_query and or_query\n",
      "def or_query(query):\n",
      "    return reduce(lambda a, e: a.union(e), [inverted_index[term] for term in preprocess(tokenize(query))])\n",
      "\n",
      "def and_query(query): \n",
      "    return reduce(lambda a, e: a.intersection(e), [inverted_index[term] for term in preprocess(tokenize(query))])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Stemming"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As we could see from the results of the last assignment, our simple index doesn't handle punctuation and the difference between singular and plural versions of the same word very well. A possible solution to those issues would be to apply better tokenization and stemming. Fortunately, Python's *NLTK* package provides implementations of these algorithms we can use:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.tokenize import word_tokenize\n",
      "from nltk.stem.snowball import EnglishStemmer\n",
      "import nltk\n",
      "nltk.download('punkt')\n",
      "stemmer = EnglishStemmer()\n",
      "\n",
      "s = '''Good muffins cost $3.88\\nin New York.  Please buy me two of them.\\n\\nThanks.'''\n",
      "\n",
      "print tokenize(s)\n",
      "print word_tokenize(s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[nltk_data] Downloading package punkt to /Users/username/nltk_data...\n",
        "[nltk_data]   Package punkt is already up-to-date!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "['Good', 'muffins', 'cost', '$3.88\\nin', 'New', 'York.', '', 'Please', 'buy', 'me', 'two', 'of', 'them.\\n\\nThanks.']\n",
        "['Good', 'muffins', 'cost', '$', '3.88', 'in', 'New', 'York', '.', 'Please', 'buy', 'me', 'two', 'of', 'them', '.', 'Thanks', '.']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print stemmer.stem(\"processes\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "process\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Ranking"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another way to improve our search results is to *rank* them. A possible way to do this is to calculate a score for each document based on the matching terms from the query. One such scoring method is *tf.idf*, as explained in the slides from Lecture 5.\n",
      "\n",
      "In order to quickly calculate the scores for a term/document combination, we'll need quick access to a couple of things:\n",
      "* tf(t,d) - How often does a term occur in a document\n",
      "* df(t) - In how many documents does a term occur\n",
      "* N - The number of documents in our index"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tf_matrix = defaultdict(Counter)\n",
      "for (id, abstract) in Abstracts.iteritems():\n",
      "    tf_matrix[id] = Counter(preprocess(tokenize(abstract)))\n",
      "\n",
      "def tf(t,d):\n",
      "    return float(tf_matrix[d][t])\n",
      "\n",
      "def df(t):\n",
      "    return float(len(inverted_index[t]))\n",
      "    \n",
      "def num_documents():\n",
      "    return float(len(Abstracts))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print tf('evolution',23144668)\n",
      "print df('evolution')\n",
      "print num_documents()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3.0\n",
        "128206.0\n",
        "205343.0\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using these three helper functions, we can now easily calculate the tf.idf weights of a term in a document by implementing the weighting formula from the slides, which you will do in the assignments below."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Assignments"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Change (in the code cell below) the *smarter_tokenize* function to use NLTK's word_tokenize function for tokenization, and the *smarter_preprocess* function to perform stemming in addition to case normalization. Does `smarter_and_query(\"evolutionary process\")` return our example paper *23144668*? Why (not)?\n",
      "\n",
      "  <small>We are purposely generating this index on a subset of the data, as generating an index with stemming on the entire set would take up to half an hour</small>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def smarter_tokenize(text):\n",
      "    # Change this\n",
      "    return text.split(' ')\n",
      "\n",
      "def smarter_preprocess(tokens):\n",
      "    result = []\n",
      "    for token in tokens:\n",
      "        # Change this\n",
      "        result.append(token.lower())\n",
      "    return result\n",
      "\n",
      "def smarter_and_query(query): # Regular and_query using smarter_tokenize and smarter_preprocess\n",
      "    return reduce(lambda a, e: a.intersection(e), [smarter_index[term] for term in smarter_preprocess(smarter_tokenize(query))])\n",
      "\n",
      "smarter_index = defaultdict(set)\n",
      "# Create a subset of around 1400 document IDs\n",
      "subset = set(Abstracts.keys()).intersection(set(xrange(23100000,23200000)))\n",
      "\n",
      "for (id, abstract) in ((k, Abstracts[k]) for k in subset):\n",
      "    for term in smarter_preprocess(smarter_tokenize(abstract)):\n",
      "        smarter_index[term].add(id)\n",
      "        \n",
      "print smarter_and_query(\"evolutionary process\")\n",
      "print 23144668 in smarter_and_query(\"evolutionary process\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "set([23179131, 23185476, 23106710, 23148266, 23193289, 23192074, 23138755, 23198988, 23194053, 23188590, 23168079, 23132463, 23197827, 23136734, 23116822, 23100716, 23166479, 23135324, 23106717, 23188175, 23133349])\n",
        "False\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Create a function `tfidf(t,d)` that returns the tf.idf score of term `t` in document `d` by using the `tf(t,d)`, `df(t)` and `num_documents()` functions we defined above. The tf.idf formula can be found on the slides for Lecture 5.\n",
      "  \n",
      "  <small>You can use the `log10(n)` function to calculate log<sub>10</sub>(n), and you can use the code cell below to verify your results.</small>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print tfidf('embodied',23144668) # 3.35343851032\n",
      "#print tfidf('evolution',23144668) # 0.302176987782\n",
      "#print tfidf('notinthedocument',23144668) # 0.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Create a function `query(query_string)`, which accepts as input a single query string that could consist of one or more words, and returns or prints a list of (up to) 10 best matching documents, along with their score. \n",
      "\n",
      "  You should use tf.idf to calculate document scores based on the query, and the results should be ordered by score in descending order.\n",
      "\n",
      "  <small>Hint: Start by copying your `or_query` function from mini-assignment 2, then expand that to rank the results, making use of the `tfidf(t,d)` function you created earlier.</small>\n",
      "\n",
      "  <small>You can either return or print a list of (id, score) tuples, or use the provided `display_summary(id,extra_text)` function to make the output a bit more 'search engine'-like. Both are valid for completing the assignment.</small>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Come up with a few example queries to run, and include the output here. Do the results make sense? Why (not)?"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}